{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f422167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdf0c7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "# Opening JSON file\n",
    "    try:\n",
    "        with open(file_name, \"r\") as f:\n",
    "            x = [line.strip() for line in f.readlines()]\n",
    "#             print(x)\n",
    "            header = x[0].split(',')\n",
    "            data_set = {\n",
    "                \"id\": [],\n",
    "                \"label\": []\n",
    "            }\n",
    "            if len(header) == 2 and header[0] == \"id\" and header[1] == \"label\":\n",
    "                for line in range(1, len(x)):\n",
    "                    data = x[line].split(\",\")\n",
    "                    data_set[\"id\"].append(data[0])\n",
    "                    data_set[\"label\"].append(data[1])\n",
    "            elif header[0] == \"id\" and len(header) < 2:\n",
    "                data_set[\"id\"] = x[1:]\n",
    "            else:\n",
    "                raise Exception(\"File doesn't have the required format\")\n",
    "            \n",
    "            return data_set\n",
    "    except Exception as e:\n",
    "        return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11aef48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(folder_path, filenames):\n",
    "    start = time.time()\n",
    "    arrays = []\n",
    "    for filename in filenames:\n",
    "        arrays.append(plt.imread(os.path.join(folder_path,filename)))\n",
    "    print(\"Time for reading images in {}:\".format(folder_path), time.time() - start)\n",
    "    return np.array(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fd35797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for reading images in train+validation: 434.09565472602844\n",
      "Time for reading images in test: 115.03572487831116\n",
      "Time for reading images in train+validation: 55.07323956489563\n"
     ]
    }
   ],
   "source": [
    "test_data = read_file(\"test.txt\")\n",
    "train_data = read_file(\"train.txt\")\n",
    "validation_data = read_file(\"validation.txt\")\n",
    "\n",
    "train_images = read_images(\"train+validation\", train_data[\"id\"])\n",
    "test_images= read_images(\"test\", test_data[\"id\"])\n",
    "validation_images = read_images(\"train+validation\", validation_data[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6abc4a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "def normalize_images(images, axis=(1,2)): \n",
    "    mean = np.mean(images, axis=axis, keepdims=True)\n",
    "    standard = np.sqrt(((images - mean)**2).mean(axis=axis, keepdims=True))\n",
    "    new_array = (images - mean) / standard\n",
    "    return new_array\n",
    "\n",
    "def normalize_images_old(images):\n",
    "#     return cv2.normalize(img,  np.zeros((16,16)), 0, 255, cv2.NORM_MINMAX)\n",
    "    return np.array([cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).flatten() for img in images])\n",
    "\n",
    "\n",
    "def normalize_images_new(images):\n",
    "#     return cv2.normalize(img,  np.zeros((16,16)), 0, 255, cv2.NORM_MINMAX)\n",
    "    return images / 255\n",
    "\n",
    "    \n",
    "def normalize_flatten_images(images):\n",
    "    return normalize_images_old(images)\n",
    "\n",
    "\n",
    "train_images_normalized = normalize_flatten_images(train_images)\n",
    "validation_images_normalized = normalize_flatten_images(validation_images)\n",
    "test_images_normalized = normalize_flatten_images(test_images)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14e2937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification time: 46.66421461105347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.60      0.68       216\n",
      "           1       0.42      0.36      0.39       201\n",
      "           2       0.63      0.80      0.70       142\n",
      "           3       0.47      0.60      0.53       150\n",
      "           4       0.64      0.71      0.67       143\n",
      "           5       0.39      0.39      0.39       145\n",
      "           6       0.50      0.45      0.47       176\n",
      "\n",
      "    accuracy                           0.55      1173\n",
      "   macro avg       0.55      0.56      0.55      1173\n",
      "weighted avg       0.55      0.55      0.55      1173\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def classifier(X_train, y_train):\n",
    "    start = time.time()\n",
    "#     clf = make_pipeline(StandardScaler(), svm.SVC(kernel='rbf'))  # 0.55\n",
    "#     clf = make_pipeline(Normalizer(), svm.SVC(kernel='rbf'))  # 0.53\n",
    "#     clf = make_pipeline(StandardScaler(), SGDClassifier(random_state=42, max_iter=1000, tol=1e-3))  # 0,44\n",
    "#     clf = make_pipeline(StandardScaler(with_mean=False), svm.LinearSVC(random_state=0, tol=1e-5, max_iter = 10000))  # 0.47\n",
    "#     clf = svm.SVC(kernel='rbf')  # 0.54\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Classification time: {}\".format(time.time() - start))\n",
    "    return clf\n",
    "\n",
    "X_train = train_images_normalized\n",
    "X_validate = validation_images_normalized\n",
    "X_test = test_images_normalized\n",
    "y_train = train_data[\"label\"]\n",
    "y_validate = validation_data[\"label\"]\n",
    "\n",
    "clf_train = classifier(X_train, y_train)\n",
    "predicted_validate = clf_train.predict(X_validate)\n",
    "print(metrics.classification_report(y_validate, predicted_validate))\n",
    "# predicted_train = clf_train.predict(X_train)\n",
    "predicted_test = clf_train.predict(X_test)\n",
    "\n",
    "# print(metrics.classification_report(y_train, predicted_train))\n",
    "print(predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b02bc95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '6', '2', '3', '1', '5', '0', '1', '5', '5', '5', '4', '2', '1', '4', '2', '0', '5', '4', '6']\n",
      "2819\n"
     ]
    }
   ],
   "source": [
    "test_data[\"label\"] = list(predicted_test)\n",
    "print(test_data[\"label\"][:20])\n",
    "print(len(test_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44a3631f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '6', '2', '3', '1', '5', '0', '1', '5', '5', '5', '4', '2', '1', '4', '2', '0', '5', '4', '6']\n",
      "2819\n"
     ]
    }
   ],
   "source": [
    "test_data[\"label\"] = list(predicted_test)\n",
    "print(test_data[\"label\"][:20])\n",
    "print(len(test_data[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9944f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_submission.txt', 'w') as f:\n",
    "    f.write('id,label\\n')\n",
    "    f.write('\\n'.join([\"{},{}\".format(id_image,label) for id_image, label in zip(test_data[\"id\"],test_data[\"label\"])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7929e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a087180a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
